{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbRjQLpfok-_"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "LulTNnmUT3Ik"
      },
      "outputs": [],
      "source": [
        "!pip install segmentation-models-pytorch\n",
        "!pip install -U albumentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbaXgDv0o2Z-"
      },
      "outputs": [],
      "source": [
        "!rm -r \"./pova_train\"\n",
        "!mkdir -p \"./pova_train\"\n",
        "!find \"/content/drive/My Drive/pova_train\" -type f | head -n 1000 | xargs -I {} cp {} \"./pova_train\" #How many pictures to move from drive to local train folder (too many pictures will take long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJs7Wya_rfE7"
      },
      "outputs": [],
      "source": [
        "!rm -r \"./pova_test\"\n",
        "!mkdir -p \"./pova_test\"\n",
        "!find \"/content/drive/My Drive/pova_train\" -type f | tail -n 200 | xargs -I {} cp {} \"./pova_test\" #Same as above, just for testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFK1Gzzil-ET"
      },
      "outputs": [],
      "source": [
        "import albumentations as A\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import segmentation_models_pytorch as smp\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "from torch.optim import Adam\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "from google.colab.patches import cv2_imshow as show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9noFFhTL-CIC"
      },
      "outputs": [],
      "source": [
        "class Augmentation():\n",
        "  def __init__(self,\n",
        "               blur: bool = False, colorJitter: bool = False,\n",
        "               grayscale: bool = False, img_size: int = 256,\n",
        "               iterations: int = 1, threshold: float = 0.0):\n",
        "    self.img_size = img_size\n",
        "    self.iterations = iterations\n",
        "    self.threshold = threshold\n",
        "    self.augmentation_list = [\n",
        "        A.RandomCrop(\n",
        "            width=self.img_size, height=self.img_size),\n",
        "        A.Rotate(\n",
        "            limit=[-360,360]),\n",
        "        A.RandomToneCurve(\n",
        "            scale=0.4),\n",
        "        A.Blur(\n",
        "            blur_limit=(5,7), p=float(blur)),\n",
        "        A.ColorJitter(\n",
        "            p=float(colorJitter)),\n",
        "        A.ToGray(\n",
        "            p=float(grayscale)),\n",
        "    ]\n",
        "\n",
        "  @staticmethod\n",
        "  def _road_coverage(mask: np.ndarray) -> float:\n",
        "    return np.sum(mask // 255) / mask.size\n",
        "\n",
        "  @classmethod\n",
        "  def road_coverage(cls, mask: torch.Tensor) -> float:\n",
        "    np_mask = mask.squeeze(0).cpu().numpy()\n",
        "    return cls._road_coverage(np_mask)\n",
        "\n",
        "  def __call__(self, image: np.ndarray,\n",
        "               mask: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
        "    transform = A.Compose(self.augmentation_list)\n",
        "    # number of tries to create augmented image with any roads\n",
        "    for i in range(self.iterations):\n",
        "      random_crop = np.random.randint(self.img_size, image.shape[0])\n",
        "      self.augmentation_list[0] = A.RandomCrop(\n",
        "            width=random_crop, height=random_crop)\n",
        "\n",
        "      result = transform(image=image, mask=mask)\n",
        "      if self._road_coverage(result[\"mask\"]) > self.threshold:\n",
        "        break\n",
        "\n",
        "    return (cv2.resize(result[\"image\"], (self.img_size, self.img_size)),\n",
        "            cv2.resize(result[\"mask\"], (self.img_size, self.img_size)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y72Kjd7HlsAx"
      },
      "outputs": [],
      "source": [
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, dataset_dir, transform=None, clip = 0, num_of_augmentations = 1, clip_offset = 0):\n",
        "        self.dataset_dir = dataset_dir\n",
        "        self.transform = transform\n",
        "        self.num_of_augmentations = num_of_augmentations\n",
        "        self.clip_offset = clip_offset\n",
        "\n",
        "        files = os.listdir(dataset_dir)\n",
        "        images = {f.split('_')[0]: os.path.join(dataset_dir, f) for f in files if f.endswith('_sat.jpg')}\n",
        "        labels = {f.split('_')[0]: os.path.join(dataset_dir, f) for f in files if f.endswith('_mask.png')}\n",
        "        self.image_data = [(images[key], labels[key]) for key in images if key in labels]\n",
        "        if(clip > 0):\n",
        "            self.image_data = self.image_data[clip_offset:clip_offset + clip]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_data) * self.num_of_augmentations\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label_path = self.image_data[idx // self.num_of_augmentations]\n",
        "\n",
        "        image = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "        label = cv2.imread(label_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        if self.transform:\n",
        "          image, label = self.transform(image, label)\n",
        "\n",
        "\n",
        "        return (torch.tensor(image, dtype=torch.float32).permute(2, 0, 1),\n",
        "                torch.tensor(label, dtype=torch.float32).unsqueeze(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_APVKAp4-YWw"
      },
      "outputs": [],
      "source": [
        "# TEST DATA AUGMENTATION\n",
        "dataset = CustomImageDataset(\"./pova_train\",\n",
        "                             transform=Augmentation(threshold=0.025, iterations=10, colorJitter=True),\n",
        "                             clip=1000)\n",
        "for i in range(5):\n",
        "  image, label = dataset[0]\n",
        "  show(image.permute(1, 2, 0).cpu().numpy())\n",
        "  show(label.squeeze(0).cpu().numpy())\n",
        "  print(Augmentation.road_coverage(label))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getIOU(y_true, y_pred, smooth=1):\n",
        "    intersection = np.logical_and(y_true, y_pred)\n",
        "    union = np.logical_or(y_true, y_pred)\n",
        "    iou_score = np.sum(intersection) / np.sum(union)\n",
        "    return iou_score\n"
      ],
      "metadata": {
        "id": "E_w5ijXAZ7Xi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLAZwzmWDQzr"
      },
      "outputs": [],
      "source": [
        "#Dice loss function\n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DiceLoss, self).__init__()\n",
        "\n",
        "    def forward(self, preds, targets, smooth=1):\n",
        "        preds = torch.sigmoid(preds)  # Apply sigmoid for probabilities\n",
        "        preds = preds.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "\n",
        "        targets = targets/255.0\n",
        "\n",
        "        intersection = (preds * targets).sum()\n",
        "        dice = 1 - ((2. * intersection + smooth) / (preds.sum() + targets.sum() + smooth))\n",
        "        return dice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtJalH6leKnI"
      },
      "outputs": [],
      "source": [
        "#Experiment params\n",
        "num_epochs = 20\n",
        "\n",
        "dataset_length_raw = 100 #How many files should be loaded, before augmentations\n",
        "train_size = int(0.8 * dataset_length_raw)\n",
        "val_size = dataset_length_raw - train_size\n",
        "\n",
        "#Initialize dataset\n",
        "train_dataset = CustomImageDataset(\"./pova_train\",\n",
        "                             transform=Augmentation(threshold=0.025, img_size = 256, colorJitter=True),\n",
        "                             clip=train_size, num_of_augmentations=3)\n",
        "\n",
        "val_dataset = CustomImageDataset(\"./pova_train\",\n",
        "                             transform=Augmentation(threshold=0.025, img_size = 256, colorJitter=True),\n",
        "                             clip=val_size, clip_offset=train_size, num_of_augmentations=3)\n",
        "\n",
        "print(len(train_dataset))\n",
        "print(len(val_dataset))\n",
        "\n",
        "\n",
        "\n",
        "#Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=2)\n",
        "\n",
        "#Define model\n",
        "model = smp.Unet(\n",
        "    encoder_name=\"efficientnet-b4\",\n",
        "    encoder_weights=None,\n",
        "    in_channels=3,\n",
        "    classes=1\n",
        ")\n",
        "\n",
        "#Define loss and optimizer\n",
        "loss_fn = DiceLoss()\n",
        "optimizer = Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLd5JC7y-OFr"
      },
      "outputs": [],
      "source": [
        "#Move model to device (GPU if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "train_loss_record = []\n",
        "val_loss_record = []\n",
        "\n",
        "train_iou_record = []\n",
        "val_iou_record = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    train_iou = 0.0\n",
        "    for images, labels in tqdm(train_loader, desc=f\"Training Epoch {epoch + 1}/{num_epochs}\"):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        #Forward pass\n",
        "        outputs = model(images)\n",
        "\n",
        "        #Compute loss\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "        #Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        outputs_binary = torch.sigmoid(outputs)\n",
        "        outputs_binary = (outputs_binary > 0.5).float()\n",
        "        train_iou += getIOU(labels.cpu().numpy(), outputs_binary.cpu().numpy())\n",
        "\n",
        "    train_iou /= len(train_loader)\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Training IOU: {train_iou:.4f}\")\n",
        "    train_iou_record.append(train_iou)\n",
        "\n",
        "\n",
        "    train_loss /= len(train_loader)\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {train_loss:.4f}\")\n",
        "\n",
        "    #Keep track of train loss scores\n",
        "    train_loss_record.append(train_loss)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    train_iou = 0.0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            outputs_binary = torch.sigmoid(outputs)\n",
        "            outputs_binary = (outputs_binary > 0.5).float()\n",
        "            train_iou += getIOU(labels.cpu().numpy(), outputs_binary.cpu().numpy())\n",
        "\n",
        "    train_iou /= len(val_loader)\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Validation IOU: {train_iou:.4f}\")\n",
        "    val_iou_record.append(train_iou)\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "    #Keep track of validation loss scores\n",
        "    val_loss_record.append(val_loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzhSXlIrB7lN"
      },
      "outputs": [],
      "source": [
        "#Plot training and validation loss\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_loss_record, label='Training Loss')\n",
        "plt.plot(val_loss_record, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Ploy training and validation accuracy\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_iou_record, label='Training IOU')\n",
        "plt.plot(val_iou_record, label='Validation IOU')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('IOU')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-MLbaQEAAO5"
      },
      "outputs": [],
      "source": [
        "#NOTE: This is here just to visually check the model\n",
        "\n",
        "#Load the test dataset\n",
        "test_dataset = CustomImageDataset(\"./pova_test\", transform=None)\n",
        "\n",
        "#Ensure model is in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "#Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "#Function to display an image, predicted mask, and actual mask\n",
        "def display_prediction(image, predicted_mask, actual_mask):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    #Input image\n",
        "    plt.subplot(1, 3, 1)\n",
        "    #make image into int\n",
        "    image = image.int()\n",
        "    plt.imshow(image.permute(1, 2, 0).cpu().numpy())  # Convert CHW to HWC for display\n",
        "    plt.title(\"Input Image\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    #Model prediction\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(predicted_mask.cpu().numpy(), cmap='gray')\n",
        "    plt.title(\"Model Prediction\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    #Ground truth\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.imshow(actual_mask.squeeze(0).cpu().numpy(), cmap='gray')\n",
        "    plt.title(\"Actual Mask\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "#Iterate through the test dataset\n",
        "for idx in range(len(test_dataset)):\n",
        "    #Get the image and label\n",
        "    image, actual_mask = test_dataset[idx]\n",
        "    image = image.to(device).unsqueeze(0)  #Add batch dimension\n",
        "    actual_mask = actual_mask.to(device)\n",
        "\n",
        "    #Run the image through the model\n",
        "    with torch.no_grad():\n",
        "        predicted_mask = model(image)\n",
        "        predicted_mask = torch.sigmoid(predicted_mask)  #Apply sigmoid for binary segmentation\n",
        "        predicted_mask = (predicted_mask > 0.5).float().squeeze(0)  #Threshold to binary mask\n",
        "\n",
        "    #Display the input image, model prediction, and actual mask\n",
        "    display_prediction(image.squeeze(0), predicted_mask.squeeze(0), actual_mask)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}